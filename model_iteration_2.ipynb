{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Iteration 2\n",
    "Pratool Gadtaula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Titanic data file and clean the data from the previous iteration of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name Sex  Age  SibSp  Parch  \\\n",
      "0                            Braund, Mr. Owen Harris   0   22      1      0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...   1   38      1      0   \n",
      "2                             Heikkinen, Miss. Laina   1   26      0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)   1   35      1      0   \n",
      "4                           Allen, Mr. William Henry   0   35      0      0   \n",
      "\n",
      "             Ticket     Fare  ...  Capt. Col.  Ms.  Mr.  Lady.  Jonkheer.  \\\n",
      "0         A/5 21171   7.2500  ...      0    0    0    1      0          0   \n",
      "1          PC 17599  71.2833  ...      0    0    0    0      0          0   \n",
      "2  STON/O2. 3101282   7.9250  ...      0    0    0    0      0          0   \n",
      "3            113803  53.1000  ...      0    0    0    0      0          0   \n",
      "4            373450   8.0500  ...      0    0    0    1      0          0   \n",
      "\n",
      "   Dr.  Master.  Major.  Don.  \n",
      "0    0        0       0     0  \n",
      "1    0        0       0     0  \n",
      "2    0        0       0     0  \n",
      "3    0        0       0     0  \n",
      "4    0        0       0     0  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.361582    0.523008   \n",
      "std     257.353842    0.486592    0.836071   13.019697    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  Embarked_S  Embarked_C  Embarked_Q     ...      \\\n",
      "count  891.000000  891.000000  891.000000  891.000000  891.000000     ...       \n",
      "mean     0.381594   32.204208    0.725028    0.188552    0.086420     ...       \n",
      "std      0.806057   49.693429    0.446751    0.391372    0.281141     ...       \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000     ...       \n",
      "25%      0.000000    7.910400    0.000000    0.000000    0.000000     ...       \n",
      "50%      0.000000   14.454200    1.000000    0.000000    0.000000     ...       \n",
      "75%      0.000000   31.000000    1.000000    0.000000    0.000000     ...       \n",
      "max      6.000000  512.329200    1.000000    1.000000    1.000000     ...       \n",
      "\n",
      "            Capt.        Col.         Ms.         Mr.       Lady.   Jonkheer.  \\\n",
      "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean     0.001122    0.002245    0.001122    0.580247    0.001122    0.001122   \n",
      "std      0.033501    0.047351    0.033501    0.493796    0.033501    0.033501   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000    0.000000    1.000000    0.000000    0.000000   \n",
      "75%      0.000000    0.000000    0.000000    1.000000    0.000000    0.000000   \n",
      "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "              Dr.     Master.      Major.        Don.  \n",
      "count  891.000000  891.000000  891.000000  891.000000  \n",
      "mean     0.007856    0.044893    0.002245    0.001122  \n",
      "std      0.088337    0.207186    0.047351    0.033501  \n",
      "min      0.000000    0.000000    0.000000    0.000000  \n",
      "25%      0.000000    0.000000    0.000000    0.000000  \n",
      "50%      0.000000    0.000000    0.000000    0.000000  \n",
      "75%      0.000000    0.000000    0.000000    0.000000  \n",
      "max      1.000000    1.000000    1.000000    1.000000  \n",
      "\n",
      "[8 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "tdf = pandas.read_csv(\"train.csv\")\n",
    "\n",
    "tdf.loc[tdf[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "tdf.loc[tdf[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "\n",
    "tdf[\"Age\"] = tdf[\"Age\"].fillna(tdf[\"Age\"].median())\n",
    "\n",
    "embarked_list = [\"Embarked_S\", \"Embarked_C\", \"Embarked_Q\"]\n",
    "\n",
    "tdf[\"Embarked_S\"] = np.zeros(len(tdf[\"Embarked\"]))\n",
    "tdf[\"Embarked_C\"] = np.zeros(len(tdf[\"Embarked\"]))\n",
    "tdf[\"Embarked_Q\"] = np.zeros(len(tdf[\"Embarked\"]))\n",
    "\n",
    "tdf[\"Embarked\"] = tdf[\"Embarked\"].fillna('S')\n",
    "tdf.loc[tdf[\"Embarked\"] == \"S\", \"Embarked_S\"] = 1\n",
    "tdf.loc[tdf[\"Embarked\"] == \"C\", \"Embarked_C\"] = 1\n",
    "tdf.loc[tdf[\"Embarked\"] == \"Q\", \"Embarked_Q\"] = 1\n",
    "\n",
    "unique_identifiers = set([])\n",
    "for el in tdf[\"Name\"].unique():\n",
    "    for name_split in el.split():\n",
    "        if '.' in name_split and name_split not in unique_identifiers:\n",
    "            unique_identifiers.add(name_split)\n",
    "            \n",
    "for identifier in unique_identifiers:\n",
    "    tdf[identifier] = [ 1 if identifier in tdf[\"Name\"][i] else 0 for i in range(len(tdf[\"Name\"])) ]\n",
    "\n",
    "print tdf.head(5)\n",
    "print tdf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using a logistic regression classifier, I'll use a random forest instead. A random forest will test out decision trees with a certain amount of randomness in the decision tree predictor in order to avoid overfitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827160493827\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "#predictors.extend(embarked_list)\n",
    "predictors.extend(unique_identifiers)\n",
    "\n",
    "# Initialize the algorithm with the default paramters\n",
    "# n_estimators is the number of trees we want to make\n",
    "# min_samples_split is the minimum number of rows we need to make a split\n",
    "# min_samples_leaf is the minimum number of samples we can have at the place where a tree branch ends\n",
    "# (the bottom points of the tree)\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=4, min_samples_leaf=2)\n",
    "\n",
    "scores = cross_validation.cross_val_score(alg, tdf[predictors], tdf[\"Survived\"],cv=3).mean()\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seemed to have done slightly better, but it's hard to tell whether this is actually due to overfitting. So I'll submit it to Kaggle to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tdf_test = pandas.read_csv(\"test.csv\")\n",
    "\n",
    "# Clean data\n",
    "tdf_test.loc[tdf_test[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "tdf_test.loc[tdf_test[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "tdf_test[\"Age\"] = tdf_test[\"Age\"].fillna(tdf_test[\"Age\"].median())\n",
    "tdf_test[\"Embarked_S\"] = np.zeros(len(tdf_test[\"Embarked\"]))\n",
    "tdf_test[\"Embarked_C\"] = np.zeros(len(tdf_test[\"Embarked\"]))\n",
    "tdf_test[\"Embarked_Q\"] = np.zeros(len(tdf_test[\"Embarked\"]))\n",
    "tdf_test[\"Embarked\"] = tdf_test[\"Embarked\"].fillna('S')\n",
    "tdf_test.loc[tdf_test[\"Embarked\"] == \"S\", \"Embarked_S\"] = 1\n",
    "tdf_test.loc[tdf_test[\"Embarked\"] == \"C\", \"Embarked_C\"] = 1\n",
    "tdf_test.loc[tdf_test[\"Embarked\"] == \"Q\", \"Embarked_Q\"] = 1\n",
    "tdf_test[\"Fare\"] = tdf_test[\"Fare\"].fillna(tdf_test[\"Fare\"].median())\n",
    "\n",
    "for identifier in unique_identifiers:\n",
    "    tdf_test[identifier] = [ 1 if identifier in tdf_test[\"Name\"][i] else 0 for i in range(len(tdf_test[\"Name\"])) ]\n",
    "\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=4, min_samples_leaf=2)\n",
    "\n",
    "# Train the algorithm using all the training data\n",
    "alg.fit(tdf[predictors], tdf[\"Survived\"])\n",
    "\n",
    "# Make predictions using the test set.\n",
    "predictions = alg.predict(tdf_test[predictors])\n",
    "\n",
    "# Create a new dataframe with only the columns Kaggle wants from the dataset.\n",
    "submission = pandas.DataFrame({\n",
    "        \"PassengerId\": tdf_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "\n",
    "submission.to_csv(\"kaggle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submitting it, it received a score lower than simply using a logistic regression on the same predictors. Thus, I have a feeling that the data has been overfit or that there isn't an easy generalization to make from the decision tree (there is a large amount of variability in the input data that could most accurately predict survival). So I try making a more general column for family size (the sum of siblings, spouses, parents, and children on board) and added a new column name length that could possibly encode more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tdf[\"FamilySize\"] = tdf[\"SibSp\"] + tdf[\"Parch\"]\n",
    "tdf[\"NameLength\"] = tdf[\"Name\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I use these new columns in conjunction with all the other ones previously generated with the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83164983165\n"
     ]
    }
   ],
   "source": [
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"FamilySize\", \"NameLength\"]\n",
    "predictors.extend(unique_identifiers)\n",
    "\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=4, min_samples_leaf=2)\n",
    "\n",
    "scores = cross_validation.cross_val_score(alg, tdf[predictors], tdf[\"Survived\"],cv=3).mean()\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to yield decent results so I try it out on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tdf_test = pandas.read_csv(\"test.csv\")\n",
    "\n",
    "# Clean data\n",
    "tdf_test.loc[tdf_test[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "tdf_test.loc[tdf_test[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "tdf_test[\"Age\"] = tdf_test[\"Age\"].fillna(tdf_test[\"Age\"].median())\n",
    "tdf_test[\"Embarked_S\"] = np.zeros(len(tdf_test[\"Embarked\"]))\n",
    "tdf_test[\"Embarked_C\"] = np.zeros(len(tdf_test[\"Embarked\"]))\n",
    "tdf_test[\"Embarked_Q\"] = np.zeros(len(tdf_test[\"Embarked\"]))\n",
    "tdf_test[\"Embarked\"] = tdf_test[\"Embarked\"].fillna('S')\n",
    "tdf_test.loc[tdf_test[\"Embarked\"] == \"S\", \"Embarked_S\"] = 1\n",
    "tdf_test.loc[tdf_test[\"Embarked\"] == \"C\", \"Embarked_C\"] = 1\n",
    "tdf_test.loc[tdf_test[\"Embarked\"] == \"Q\", \"Embarked_Q\"] = 1\n",
    "tdf_test[\"Fare\"] = tdf_test[\"Fare\"].fillna(tdf_test[\"Fare\"].median())\n",
    "\n",
    "for identifier in unique_identifiers:\n",
    "    tdf_test[identifier] = [ 1 if identifier in tdf_test[\"Name\"][i] else 0 for i in range(len(tdf_test[\"Name\"])) ]\n",
    "    \n",
    "tdf_test[\"FamilySize\"] = tdf_test[\"SibSp\"] + tdf_test[\"Parch\"]\n",
    "tdf_test[\"NameLength\"] = tdf_test[\"Name\"].apply(lambda x: len(x))\n",
    "\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=4, min_samples_leaf=2)\n",
    "\n",
    "# Train the algorithm using all the training data\n",
    "alg.fit(tdf[predictors], tdf[\"Survived\"])\n",
    "\n",
    "# Make predictions using the test set.\n",
    "predictions = alg.predict(tdf_test[predictors])\n",
    "\n",
    "# Create a new dataframe with only the columns Kaggle wants from the dataset.\n",
    "submission = pandas.DataFrame({\n",
    "        \"PassengerId\": tdf_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "\n",
    "submission.to_csv(\"kaggle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This performs even <b>worse</b> than before! Adding more columns with barely any new information is deteriorating the generality of the random forests; I'm definitely overfitting the data. Instead, I'll try a different algorithm called Gradient Boosting which builds trees one after another in succession. This is also prone to overfitting the data, so I limit it to a maximum depth of 3 and only 25 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.830527497194\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "alg = GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3)\n",
    "\n",
    "scores = cross_validation.cross_val_score(alg, tdf[predictors], tdf[\"Survived\"],cv=3).mean()\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also seems hopeful, but I want to mix it with the probabilities of an algorithm that is less prone to overfitting. A linear regression model fits that criteria. For now I just want to test it with all the parameters I have so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821548821549\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "alg = LogisticRegression(random_state=1)\n",
    "\n",
    "scores = cross_validation.cross_val_score(alg, tdf[predictors], tdf[\"Survived\"],cv=3).mean()\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty good! It's nearly on par with the Gradient Boosting algorithm, despite some redundancies in the data. But before I mix the probabilities, I want to check out which factors seem to be most important to the linear classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.822671156004\n"
     ]
    }
   ],
   "source": [
    "linear_predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"FamilySize\"]\n",
    "linear_predictors.extend(unique_identifiers)\n",
    "\n",
    "alg = LogisticRegression(random_state=1)\n",
    "\n",
    "scores = cross_validation.cross_val_score(alg, tdf[linear_predictors], tdf[\"Survived\"],cv=3).mean()\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that avoiding the number of siblings and spouses and parents and children and name length yields almost the same prediction rate. I'll stick to these columns for the logistic regression and use all of the columns for the Gradient Boosting algorithm. However, I want a better metric for how well the algorithm is predicting the outcomes. For that I decided to make a metric (that I like to call \"anti-confidence\"). It takes as a function the probability of the prediction, the actual prediction, and the actual outcome. The value is then $(|r-o|+r-p)^2$, where $r$ is the prediction (0 or 1), $o$ is the outcome (0 or 1), and $p$ is the probablity ($0 \\leq p \\leq 1$). This penalizes for probabilities that are closer to 0.5, with a penalty that would decrease if the outcome was correct but increase a lot more with an outcome that was incorrect. I define the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conf_penalty(probability, prediction, outcome):\n",
    "    \"\"\"\n",
    "    Takes the probability, prediction, and outcome of a specific prediction algorithm and\n",
    "    returns a penalty that quantifies how badly the algorithm did. Higher values are worse.\n",
    "    \"\"\"\n",
    "    return ( abs(prediction-outcome)+prediction-probability )**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to easily compare the effectiveness of using different prediction methods and factors, I made some function wrappers for quick testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "def test_alg(algs_predictors, df):\n",
    "    \"\"\"\n",
    "    Automate testing of various predictive algorithms at once\n",
    "    \n",
    "    algs_predictors is a list of tuples that contain 1) a scikit-learn algorithm and\n",
    "                    2) a list of the column names to be used as predictors\n",
    "                    \n",
    "    df              is a pandas data frame object that has all the column names to be used in algs_predictors\n",
    "    \n",
    "    This returns a tuple of a all the predictions and all the outcomes.\n",
    "    \n",
    "    full_test_predictions is a list of numpy arrays of the predictions on the input data with various test-train splits\n",
    "    full_outcomes         is a list of numpy arrays of all the outcomes used to test the data with various test-train splits\n",
    "    \"\"\"\n",
    "    kf = KFold(df.shape[0], n_folds=3, random_state=1)\n",
    "    full_test_predictions = []\n",
    "    full_outcomes = []\n",
    "    for alg, predictor in algs_predictors:\n",
    "        alg_predictions = []\n",
    "        alg_outcomes = []\n",
    "        for train, test in kf:\n",
    "            train_target = df[\"Survived\"].iloc[train]\n",
    "            alg.fit(df[predictor].iloc[train,:], train_target)\n",
    "            test_predictions = alg.predict_proba(df[predictor].iloc[test,:].astype(float))[:,1]\n",
    "            alg_predictions.append(test_predictions)\n",
    "            alg_outcomes.append(df[\"Survived\"].iloc[test])\n",
    "        alg_predictions = np.concatenate(alg_predictions)\n",
    "        alg_outcomes = np.concatenate(alg_outcomes)\n",
    "        full_test_predictions.append(alg_predictions)\n",
    "        full_outcomes.append(alg_outcomes)\n",
    "    return (full_test_predictions, full_outcomes)\n",
    "\n",
    "def eval_tests(predictions, outcomes):\n",
    "    \"\"\"\n",
    "    This function evaluates the effectiveness of the predictions by using the conf_penalty function as a metric\n",
    "    and sums up the the metrics for each data point. This is primarily used to complement test_alg()\n",
    "    \n",
    "    predictions is a list of numpy arrays of the predictions made on the input data by various algorithms\n",
    "    \n",
    "    Output:\n",
    "    outcomes is a list of values that is the sum of the metrics for each data point (the number of items\n",
    "             in the list is the number of algorithms used)\n",
    "    \"\"\"\n",
    "    pred_penalties = []\n",
    "    for predicts, outs in zip(predictions, outcomes):\n",
    "        pred_penalties.append( np.sum([ conf_penalty( predicts[i], int(predicts[i]>0.5), \\\n",
    "                                       outs[i] ) for i in range(len(outs)) ]) )\n",
    "    return pred_penalties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tested my anti-confidence rating for the different predictors on logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[199.21772701718064, 208.82362426371984]\n"
     ]
    }
   ],
   "source": [
    "algs_predicts = [ (LogisticRegression(random_state=1), linear_predictors),\n",
    "                  (LogisticRegression(random_state=1), predictors) ]\n",
    "\n",
    "tp, o = test_alg(algs_predicts, tdf)\n",
    "\n",
    "print eval_tests(tp, o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the linear predictors performed better than all the predictors for the logistic regression. I'll use an ensemble of logistic regression and the gradient boosting classifier to make new predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensemble_algs(algs_predictors, df):\n",
    "    kf = KFold(df.shape[0], n_folds=3, random_state=1)\n",
    "    predictions = []\n",
    "    for train, test in kf:\n",
    "        train_target = df[\"Survived\"].iloc[train]\n",
    "        full_test_predictions = []\n",
    "        # Make predictions for each algorithm on each fold\n",
    "        for alg, preds in algs_predictors:\n",
    "            # Fit the algorithm on the training data.\n",
    "            alg.fit(df[preds].iloc[train,:], train_target)\n",
    "            # Select and predict on the test fold.  \n",
    "            # The .astype(float) is necessary to convert the dataframe to all floats and avoid an sklearn error.\n",
    "            test_predictions = alg.predict_proba(df[preds].iloc[test,:].astype(float))[:,1]\n",
    "            full_test_predictions.append(test_predictions)\n",
    "        # Use a simple ensembling scheme -- just average the predictions to get the final classification.\n",
    "        test_predictions = np.sum(full_test_predictions, axis=0) / len(full_test_predictions)\n",
    "        # Any value over .5 is assumed to be a 1 prediction, and below .5 is a 0 prediction.\n",
    "        test_predictions[test_predictions <= .5] = 0\n",
    "        test_predictions[test_predictions > .5] = 1\n",
    "        predictions.append(test_predictions)\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[154.0]\n"
     ]
    }
   ],
   "source": [
    "algs_predicts = [(LogisticRegression(random_state=1), linear_predictors),\n",
    "                  (GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors) ]\n",
    "print eval_tests([ensemble_algs(algs_predicts, tdf)], [tdf[\"Survived\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ensemble performed much better than just the logistic regression. I'll use this method and submit it to Kaggle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tdf_test = pandas.read_csv(\"test.csv\")\n",
    "\n",
    "# Clean data\n",
    "tdf_test.loc[tdf_test[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "tdf_test.loc[tdf_test[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "tdf_test[\"Age\"] = tdf_test[\"Age\"].fillna(tdf_test[\"Age\"].median())\n",
    "tdf_test[\"Embarked_S\"] = np.zeros(len(tdf_test[\"Embarked\"]))\n",
    "tdf_test[\"Embarked_C\"] = np.zeros(len(tdf_test[\"Embarked\"]))\n",
    "tdf_test[\"Embarked_Q\"] = np.zeros(len(tdf_test[\"Embarked\"]))\n",
    "tdf_test[\"Embarked\"] = tdf_test[\"Embarked\"].fillna('S')\n",
    "tdf_test.loc[tdf_test[\"Embarked\"] == \"S\", \"Embarked_S\"] = 1\n",
    "tdf_test.loc[tdf_test[\"Embarked\"] == \"C\", \"Embarked_C\"] = 1\n",
    "tdf_test.loc[tdf_test[\"Embarked\"] == \"Q\", \"Embarked_Q\"] = 1\n",
    "tdf_test[\"Fare\"] = tdf_test[\"Fare\"].fillna(tdf_test[\"Fare\"].median())\n",
    "\n",
    "# Add new columns\n",
    "for identifier in unique_identifiers:\n",
    "    tdf_test[identifier] = [ 1 if identifier in tdf_test[\"Name\"][i] else 0 for i in range(len(tdf_test[\"Name\"])) ]\n",
    "    \n",
    "tdf_test[\"FamilySize\"] = tdf_test[\"SibSp\"] + tdf_test[\"Parch\"]\n",
    "tdf_test[\"NameLength\"] = tdf_test[\"Name\"].apply(lambda x: len(x))\n",
    "\n",
    "# Select prediction identifiers\n",
    "linear_predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"FamilySize\"]\n",
    "linear_predictors.extend(unique_identifiers)\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"FamilySize\", \"NameLength\"]\n",
    "predictors.extend(unique_identifiers)\n",
    "\n",
    "# Arrange into an algorithm ensemble\n",
    "algs_predicts = [(LogisticRegression(random_state=1), linear_predictors),\n",
    "                  (GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors) ]\n",
    "\n",
    "full_predictions = []\n",
    "for alg, preds in algs_predicts:\n",
    "    # Fit the algorithm using the full training data.\n",
    "    alg.fit(tdf[preds], tdf[\"Survived\"])\n",
    "    # Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.\n",
    "    predictions = alg.predict_proba(tdf_test[preds].astype(float))[:,1]\n",
    "    full_predictions.append(predictions)\n",
    "\n",
    "test_predictions = np.sum(full_predictions, axis=0) / len(full_predictions)\n",
    "predictions = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Create a new dataframe with only the columns Kaggle wants from the dataset.\n",
    "submission = pandas.DataFrame({\n",
    "        \"PassengerId\": tdf_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "\n",
    "submission.to_csv(\"kaggle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This entry had the same performace as my previous best entry, with an accuracy of 0.78947. Now I'll try weighting the gradient boosting classifier more because it did perform better on the test data set and submit it to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tdf_test = pandas.read_csv(\"test.csv\")\n",
    "\n",
    "# Clean data\n",
    "tdf_test.loc[tdf_test[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "tdf_test.loc[tdf_test[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "tdf_test[\"Age\"] = tdf_test[\"Age\"].fillna(tdf_test[\"Age\"].median())\n",
    "tdf_test[\"Embarked_S\"] = np.zeros(len(tdf_test[\"Embarked\"]))\n",
    "tdf_test[\"Embarked_C\"] = np.zeros(len(tdf_test[\"Embarked\"]))\n",
    "tdf_test[\"Embarked_Q\"] = np.zeros(len(tdf_test[\"Embarked\"]))\n",
    "tdf_test[\"Embarked\"] = tdf_test[\"Embarked\"].fillna('S')\n",
    "tdf_test.loc[tdf_test[\"Embarked\"] == \"S\", \"Embarked_S\"] = 1\n",
    "tdf_test.loc[tdf_test[\"Embarked\"] == \"C\", \"Embarked_C\"] = 1\n",
    "tdf_test.loc[tdf_test[\"Embarked\"] == \"Q\", \"Embarked_Q\"] = 1\n",
    "tdf_test[\"Fare\"] = tdf_test[\"Fare\"].fillna(tdf_test[\"Fare\"].median())\n",
    "\n",
    "# Add new columns\n",
    "for identifier in unique_identifiers:\n",
    "    tdf_test[identifier] = [ 1 if identifier in tdf_test[\"Name\"][i] else 0 for i in range(len(tdf_test[\"Name\"])) ]\n",
    "    \n",
    "tdf_test[\"FamilySize\"] = tdf_test[\"SibSp\"] + tdf_test[\"Parch\"]\n",
    "tdf_test[\"NameLength\"] = tdf_test[\"Name\"].apply(lambda x: len(x))\n",
    "\n",
    "# Select prediction identifiers\n",
    "linear_predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"FamilySize\"]\n",
    "linear_predictors.extend(unique_identifiers)\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"FamilySize\", \"NameLength\"]\n",
    "predictors.extend(unique_identifiers)\n",
    "\n",
    "# Arrange into an algorithm ensemble\n",
    "algs_predicts = [(LogisticRegression(random_state=1), linear_predictors),\n",
    "                  (GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors) ]\n",
    "\n",
    "full_predictions = []\n",
    "for alg, preds in algs_predicts:\n",
    "    # Fit the algorithm using the full training data.\n",
    "    alg.fit(tdf[preds], tdf[\"Survived\"])\n",
    "    # Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.\n",
    "    predictions = alg.predict_proba(tdf_test[preds].astype(float))[:,1]\n",
    "    full_predictions.append(predictions)\n",
    "\n",
    "test_predictions = (full_predictions[0]*3 + full_predictions[1]) / 4\n",
    "predictions = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Create a new dataframe with only the columns Kaggle wants from the dataset.\n",
    "submission = pandas.DataFrame({\n",
    "        \"PassengerId\": tdf_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "\n",
    "submission.to_csv(\"kaggle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This entry also had the same performace as my previous best entry, with an accuracy of 0.78947."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading <a href=\"http://elenacuoco.altervista.org/blog/archives/1195\">this</a> blog, I realized that not calculating the age correctly could have huge consequences on the prediction; it's one of the most important factors in deciding survival. Instead of filling all the ages with the median, I'll fill them according to their title. There are quite a few titles that could be collapsed into four general ones, Mr, Mrs, Miss, and Master. Master is not a colloquially spoken today, but back at the time of the titanic referred to boys who were not deemed to be \"men\" by society yet. There was a large portion of the passengers with each of these titles, so it seems like a better way to imput the ages that were not given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tdf = pandas.read_csv(\"train.csv\")\n",
    "\n",
    "def clean_data(df):\n",
    "    df.loc[df[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "    df.loc[df[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "\n",
    "    df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"]\n",
    "    df[\"NameLength\"] = df[\"Name\"].apply(lambda x: len(x))\n",
    "\n",
    "    embarked_list = [\"Embarked_S\", \"Embarked_C\", \"Embarked_Q\"]\n",
    "\n",
    "    df[\"Embarked_S\"] = np.zeros(len(df[\"Embarked\"]))\n",
    "    df[\"Embarked_C\"] = np.zeros(len(df[\"Embarked\"]))\n",
    "    df[\"Embarked_Q\"] = np.zeros(len(df[\"Embarked\"]))\n",
    "\n",
    "    df[\"Embarked\"] = df[\"Embarked\"].fillna('S')\n",
    "    df.loc[df[\"Embarked\"] == \"S\", \"Embarked_S\"] = 1\n",
    "    df.loc[df[\"Embarked\"] == \"C\", \"Embarked_C\"] = 1\n",
    "    df.loc[df[\"Embarked\"] == \"Q\", \"Embarked_Q\"] = 1\n",
    "    df[\"Fare\"] = df[\"Fare\"].fillna(df[\"Fare\"].median())\n",
    "\n",
    "unique_identifiers = set([])\n",
    "for el in tdf[\"Name\"].unique():\n",
    "    for name_split in el.split():\n",
    "        if '.' in name_split and name_split not in unique_identifiers and not name_split == 'L.':\n",
    "            unique_identifiers.add(name_split)\n",
    "\n",
    "def make_identifiers(df):\n",
    "    for identifier in unique_identifiers:\n",
    "        df[identifier] = df[\"Name\"].apply(lambda x: 1 if identifier in x else 0)\n",
    "\n",
    "clean_data(tdf)\n",
    "make_identifiers(tdf)\n",
    "\n",
    "def classify_age_title(df):\n",
    "    age_titles = {}\n",
    "    age_titles[\"Mr\"] = [\"Mr.\", \"Rev.\", \"Sir.\", \"Col.\", \"Capt.\", \"Major.\", \"Don.\", \"Jonkheer.\", \"Dr.\"]\n",
    "    age_titles[\"Mrs\"] = [\"Mrs.\", \"Mme.\", \"Lady.\", \"Countess.\"]\n",
    "    age_titles[\"Miss\"] = [\"Miss.\", \"Mlle.\", \"Ms.\"]\n",
    "    age_titles[\"Master\"] = [\"Master.\"]\n",
    "\n",
    "    for category in age_titles:\n",
    "        temp_category_vals = df[age_titles[category][0]].apply(lambda x: x)\n",
    "        for title in age_titles[category]:\n",
    "            temp_category_vals += df[title].apply(lambda x: x)\n",
    "        df[category] = temp_category_vals\n",
    "\n",
    "        # Make the category boolean\n",
    "        df.loc[df[category] > 0, category] = 1\n",
    "\n",
    "        # Determine the mean of the category with the values that exist\n",
    "        cur_mean = df[\"Age\"][df[category] == 1].dropna()\n",
    "        cur_mean = cur_mean.mean()\n",
    "\n",
    "        # Set the age values in the category that do not have values with current mean\n",
    "        df.loc[( (df[category] == 1) & (np.isnan(df[\"Age\"])) ), \"Age\"] = cur_mean\n",
    "    \n",
    "    cur_median = df[\"Age\"].dropna()\n",
    "    cur_median = cur_median.median()\n",
    "    df.loc[(np.isnan(df[\"Age\"])), \"Age\"] = cur_median\n",
    "    \n",
    "classify_age_title(tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[154.0]\n"
     ]
    }
   ],
   "source": [
    "# Select prediction identifiers\n",
    "linear_predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"FamilySize\"]\n",
    "linear_predictors.extend(unique_identifiers)\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"FamilySize\", \"NameLength\"]\n",
    "predictors.extend(unique_identifiers)\n",
    "\n",
    "algs_predicts = [(LogisticRegression(random_state=1), linear_predictors),\n",
    "                  (GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors) ]\n",
    "print eval_tests([ensemble_algs(algs_predicts, tdf)], [tdf[\"Survived\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This did not seem to have much of an effect on the training data set. However, I think that misclassifying due to putting the wrong age from just using the median could make a difference. I'll go ahead and submit it to Kaggle anyway because I do think that I can make more informed decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tdf_test = pandas.read_csv(\"test.csv\")\n",
    "\n",
    "clean_data(tdf_test)\n",
    "make_identifiers(tdf_test)\n",
    "classify_age_title(tdf_test)\n",
    "\n",
    "# Arrange into an algorithm ensemble\n",
    "algs_predicts = [(LogisticRegression(random_state=1), linear_predictors),\n",
    "                  (GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors) ]\n",
    "\n",
    "full_predictions = []\n",
    "for alg, preds in algs_predicts:\n",
    "    # Fit the algorithm using the full training data.\n",
    "    alg.fit(tdf[preds], tdf[\"Survived\"])\n",
    "    # Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.\n",
    "    predictions = alg.predict_proba(tdf_test[preds].astype(float))[:,1]\n",
    "    full_predictions.append(predictions)\n",
    "\n",
    "test_predictions = (full_predictions[0]*3 + full_predictions[1]) / 4\n",
    "predictions = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Create a new dataframe with only the columns Kaggle wants from the dataset.\n",
    "submission = pandas.DataFrame({\n",
    "        \"PassengerId\": tdf_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "\n",
    "submission.to_csv(\"kaggle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure enough my score increased by 0.01435! Improving the imputation of the age and including the titles garnered the greatest improvements to the predictions. This is likely because they are more strongly correlated to survival rate than other factors such as fare."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
